{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44fc48f3-0d4e-4631-8ddd-41d28a1385f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\KARTIK\\.conda\\envs\\multimodal_ai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\Users\\KARTIK\\.conda\\envs\\multimodal_ai\\lib\\site-packages\\open_clip\\factory.py:380: UserWarning: These pretrained weights were trained with QuickGELU activation but the model config does not have that enabled. Consider using a model config with a \"-quickgelu\" suffix or enable with a flag.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1000 embeddings\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import time\n",
    "import open_clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Load dataset\n",
    "csv_path = \"G:/multimodal_ai/datasets/final_captions.csv\"\n",
    "df = pd.read_csv(csv_path).sample(1000, random_state=42)\n",
    "\n",
    "# Load CLIP model\n",
    "model, preprocess, _ = open_clip.create_model_and_transforms(\"ViT-B-32\", pretrained=\"openai\")\n",
    "tokenizer = open_clip.get_tokenizer(\"ViT-B-32\")\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(image_path, text):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = preprocess(image).unsqueeze(0)\n",
    "        text_tokens = tokenizer([text])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image).cpu().numpy()\n",
    "            text_features = model.encode_text(text_tokens).cpu().numpy()\n",
    "\n",
    "        combined_features = (image_features + text_features) / 2\n",
    "        return combined_features.flatten()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract and store embeddings\n",
    "embeddings = []\n",
    "image_paths = []\n",
    "for _, row in df.iterrows():\n",
    "    image_path = f\"G:/multimodal_ai/datasets/images/{row['image']}\"\n",
    "    caption = row['caption']\n",
    "    \n",
    "    features = extract_features(image_path, caption)\n",
    "    if features is not None:\n",
    "        embeddings.append(features)\n",
    "        image_paths.append(row['image'])\n",
    "\n",
    "embeddings = np.array(embeddings, dtype=np.float32)\n",
    "print(f\"Extracted {len(embeddings)} embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "145b509b-b7bb-4dea-91d4-0458c38c98bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute-Force Retrieval Time: 0.001992 seconds\n"
     ]
    }
   ],
   "source": [
    "# Generate a random query vector from dataset\n",
    "query_vector = embeddings[0].reshape(1, -1)\n",
    "\n",
    "# Measure retrieval time using brute-force similarity search\n",
    "start_time = time.time()\n",
    "similarities = np.dot(embeddings, query_vector.T)  # Compute cosine similarity\n",
    "top_k_brute = similarities.flatten().argsort()[-5:][::-1]  # Top-5 indices\n",
    "end_time = time.time()\n",
    "\n",
    "brute_force_time = end_time - start_time\n",
    "print(f\"Brute-Force Retrieval Time: {brute_force_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20d37f50-5d18-46af-bc18-1d642f2405bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS Retrieval Time: 0.000982 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS Index\n",
    "faiss_index = faiss.IndexFlatL2(512)  # 512-D feature space\n",
    "faiss_index.add(embeddings)\n",
    "\n",
    "# Measure retrieval time using FAISS\n",
    "start_time = time.time()\n",
    "D, I = faiss_index.search(query_vector, 5)  # Search for top-5 matches\n",
    "end_time = time.time()\n",
    "\n",
    "faiss_time = end_time - start_time\n",
    "print(f\"FAISS Retrieval Time: {faiss_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd767030-d1d9-46ee-83b4-ce91fb26ce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Speed Improvement: 50.70%\n"
     ]
    }
   ],
   "source": [
    "improvement = ((brute_force_time - faiss_time) / brute_force_time) * 100\n",
    "print(f\"Retrieval Speed Improvement: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ecf1d-63ec-4353-8881-468eebd2df4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (multimodal_ai)",
   "language": "python",
   "name": "multimodal_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
